---
title: "Practical Machine Learning Course Project"
author: "Gustavo Jimenez-Maggiora"
date: "April 26, 2015"
output: html_document
---

```{r, cache=TRUE}
require(caret)
require(mlbench)
require(party)
require(randomForest)
```

## Data
We are using the training and testing sets provided.

```{r, cache=TRUE}
training <- read.csv('./pml-training.csv')
testing <- read.csv('./pml-testing.csv')

```

Upon review of the data set, several columns were removed.

First, I removed any columns that had zero or close to zero variance in the training set.

```{r, cache=TRUE}
remove <- nearZeroVar(training)
training <- training[,-remove]
testing <- training[,-remove]

```

Secondly, I removed any columns that have NA values (**NOTE**: I assume that the same columns
have NA's in the testing set).

```{r, cache=TRUE}
ok <- apply(training, 2, function(x) !any(is.na(x)))
training <- training[,ok]
testing <- testing[,ok]

```

Finally, I remove any variables that are summary statistics calculated by
the authors of the data set (eg. skewness, kurtosis, etc.)

```{r, cache=TRUE}
not_ok <- grepl('^(X|cvtd_timestamp|kurtosis|skewness|max_|min_|amplitude)',colnames(trainingData));

training<-training[,!not_ok]
testing<-testing[,!not_ok]

```

The final training data set is the following (**NOTE**: the testing set has the same structure):

```{r, cache=TRUE}
# Dimensions
dim(training)
dim(testing)

# Summary - training data
summary(training)
```

## Methods
To find the best machine learning method, we compare accuracy and ooe results for various models:



## Feature Selection

## Predictive Model

## Conclusion
